<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ray Generation</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <p><a href="index.html">Back to index</a></p>
<hr />
<h1>Ray Tracing Fundamentals</h1>
<h2>Ray Generation</h2>
<h3>Ray Generation (Ray Tracing Fundamentals)</h3>
<p>Ray generation is a crucial step in the ray tracing pipeline, where rays are initially created to simulate the way light interacts with objects in a scene. Here's a deeper look into the key components and steps involved in ray generation:</p>
<h4><strong>1. Camera Model</strong></h4>
<ul>
<li><strong>Position</strong>: The camera's position in the scene determines the origin of the rays.</li>
<li><strong>Orientation</strong>: This includes the view direction, up vector, and right vector that define the camera's coordinate system.</li>
<li><strong>Field of View</strong>: This determines the angle of the viewing frustum, affecting how wide the scene appears.</li>
</ul>
<h4><strong>2. Ray Origins and Directions</strong></h4>
<ul>
<li><strong>Pixel to Ray Mapping</strong>: Each pixel on the screen corresponds to a unique ray. The goal is to map screen coordinates to world coordinates.</li>
<li><strong>Ray Origin</strong>: Typically, all rays originate from the camera position.</li>
<li><strong>Ray Direction</strong>: Calculated based on the pixel's position on the screen:
<ul>
<li><strong>Viewport Calculation</strong>: Convert pixel coordinates to normalized device coordinates and then to screen space.</li>
<li><strong>Transform to World Space</strong>: Convert the screen space coordinates to world space using the camera's transformation matrix.</li>
<li><strong>Constructing Ray Directions</strong>: The direction is often normalized, and it's computed by subtracting the eye position from the point on the screen in world space.</li>
</ul>
</li>
</ul>
<h4><strong>3. Viewing Rays Setup</strong></h4>
<ul>
<li><strong>Primary Rays</strong>: These are the initial rays cast directly from the camera into the scene. Every pixel on the screen typically casts one primary ray.</li>
<li><strong>Ray Equation</strong>: The parametric form of the ray equation is used:
[
\text{Ray}(t) = \text{Origin} + t \times \text{Direction}
]
where ( t ) is a scalar that varies along the ray's path.</li>
</ul>
<h4><strong>4. Ray Buffering</strong></h4>
<ul>
<li><strong>Ray Structures</strong>: Rays are often stored in buffers. Each ray typically includes:
<ul>
<li><code>origin</code>: The start point of the ray.</li>
<li><code>direction</code>: The normalized direction vector along which the ray travels.</li>
<li><code>t_min</code> and <code>t_max</code>: These define the range along the ray's path for intersection testing.</li>
</ul>
</li>
</ul>
<h4><strong>5. GLSL Implementation</strong></h4>
<p>In GLSL, ray generation typically happens in a fragment shader or compute shader:</p>
<ul>
<li><strong>Fragment Shader</strong>: Each fragment corresponds to a pixel, ideal for generating primary rays.</li>
<li><strong>Compute Shader</strong>: More flexible for complex ray generation patterns and managing multiple rays per pixel (e.g., for anti-aliasing).</li>
</ul>
<p>Example GLSL Code Snippet for Ray Generation:</p>
<pre><code class="language-glsl">#version 450

in vec2 fragCoord; // Screen coordinates
uniform vec3 cameraPos; // Camera position
uniform mat4 viewMatrix; // View transformation matrix
uniform mat4 projMatrix; // Projection matrix

out vec3 rayOrigin;
out vec3 rayDirection;

void main() {
    // Transform screen coordinates to normalized device coordinates (NDC)
    vec2 ndc = (fragCoord / vec2(SCREEN_WIDTH, SCREEN_HEIGHT)) * 2.0 - 1.0;
    
    // Transform NDC to camera space
    vec4 clipSpace = vec4(ndc, -1.0, 1.0); // Assuming near plane at z = -1
    vec4 viewSpace = inverse(projMatrix) * clipSpace;
    viewSpace.z = -1.0; // Correcting the depth
    viewSpace.w = 0.0;
    
    // Transform to world space
    vec4 worldSpace = inverse(viewMatrix) * viewSpace;
    
    // Calculate the ray direction
    rayOrigin = cameraPos;
    rayDirection = normalize(worldSpace.xyz - cameraPos);
}
</code></pre>
<h4><strong>6. Anti-Aliasing and Sampling</strong></h4>
<ul>
<li><strong>Super-sampling</strong>: Casting multiple rays per pixel (jittered) to achieve anti-aliasing.</li>
<li><strong>Random Sampling</strong>: Introduce randomness to the ray directions for effects like depth of field and motion blur.</li>
</ul>
<h3>Conclusion</h3>
<p>Ray generation is the foundational step in ray tracing, setting the stage for subsequent intersection tests, shading, and lighting calculations. Understanding how to generate and manage rays effectively is crucial for crafting realistic and performant ray-traced imagery.</p>
<hr />
<p><a href="index.html">Back to index</a></p>


    <hr />

    <i>
        <span>gpt-4o</span>
        <br/>
        <span>18/05/2024 18:39:21 +02:00</span>
    </i>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['[', ']'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    
    <script>hljs.highlightAll();</script>
</body>
</html>